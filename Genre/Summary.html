<!DOCTYPE html>

<html>

    <head>
        <title>Sarangi Papers - Genre </title>
        <style>
            #container{
            }

            .paper{
                    border: 1px solid blue;
                    font-family: verdana;
                    font-size: 1.0em;
                    white-space: pre-wrap;
            }
            .paper b{
                    font-size:0.8em;
            }
    
        </style>
    </head>

    <body>
    <div id="container">

            <!-- Form template
            <div class="paper" id="form">
                    <b>Paper Code:</b>
                    <b>Title:</b>
                    <b>Author(s):</b> 
                    <b>Date:</b>
                    <b>Pages:</b>
                    <b>Data Source:</b>
                    <b>Algorithms used:</b>
                    <b>Formality rating:</b>
                    <b>Interest rating:</b>
                    <b>Genre:</b>

                    <b>Intro notes:</b>
                    <b>Body Notes:</b>
            </div>
            --!>

            <div class="paper" id=g1"> 
                    <b>Paper Code:</b> G1
                    <b>Title:</b> A Study on Music Genre Recognition and Classification Techniques
                    <b>Author(s):</b> Aziz Nasridinov and Young-Ho Park
                    <b>Date:</b> 2014
                    <b>Pages:</b> 12
                    <b>Data Source:</b>
                    <b>Algorithms used:</b>
                    <b>Formality rating:</b> 4/5
                    <b>Interest rating:</b> 2/5
                    <b>Genre:</b>(4) prehistoric time, middle age, renaissance, baroque, classic and modern

                    <b>Intro Notes:</b>
                    -Hidden Markov models are the most popular methods used in chord recognition
                    <b>Body Notes:</b>
                    -Proposed method: 
                    a) Chord labeling (1s and 0s)
                    b) A k-windowSubsequenceMatching algorithm used in order to find subsequence in music sequence.
                    c) Decision tree for genere classification
            </div>

            <div class="paper" id="g2">
                    <b>Paper Code:</b> G2
                    <b>Title:</b> Improving the reliability of music genre classification using rejection and verification
                    <b>Author(s):</b> Alessandro L. Koerich
                    <b>Date:</b> 2013
                    <b>Pages:</b> 6
                    <b>Data Source:</b> Benchmark dataset ISMIR 2004, GTZAN [15], and LMD
                    <b>Algorithms used:</b>
                    Multi-class support vector machine (SVM) algorithm with one-against all strategy
                    A multilayer perceptron neural network (MLP) trained with the backpropagation momentum algorithm.
                    <b>Formality rating:</b> 4/5
                    <b>Interest rating:</b> 4/5
                    <b>Genre:</b>

                    <b>Intro notes:</b>
                    - Fu et al [2] provide a comprehensive review on audio-based classification and systematically 
                    summarize the state-of-the-art techniques for music classification, stressing the difference 
                    in the features and the types of classifiers used for different classification tasks such as 
                    music genre classification, mood classification, artist identification, instrument recognition 
                    and music annotation.
                    <b>Body Notes:</b>
                    - The feature extraction module uses the MARSYAS framework to extract seventeen audio features from 
                    46ms frames of the audio signal with no overlap.
                    - The baseline classification determines the genre with certain possibilities
                    - The rejection system rejects classifications that are uncertain
                    - The verification system reclassifies some of the rejected classifications based on the output of the 
                    baseline classifier and confusion matrix
            </div>

            <div class="paper" id="g3">
                    <b>Paper Code:</b> G3
                    <b>Title:</b> Music Genre Classification Using Machine Learning Techniques
                    <b>Author(s):</b> Sam Clark, Danny Park, Adrien Guerard
                    <b>Date:</b> 2012
                    <b>Pages:</b> 12
                    <b>Data Source:</b> LastFM (manual) and Echonest audio_summary
                    <b>Algorithms used:</b> Growing neural gas and neural networks
                    <b>Formality rating:</b> 2/5
                    <b>Interest rating:</b> 3/5
                    <b>Genre:</b> classical, country, rap, and reggae

                    <b>Intro notes:</b>
                    <b>Body Notes:</b>
                    - growing neural gas assists the neural network
                    - 12 model vectors created by the GNG
                    - Also a visualization made using Python
            </div>

            <div class="paper" id="g4">
                    <b>Paper Code:</b> G4
                    <b>Title:</b> Improving Music Genre Classification Using Automatically Induced Harmony Rules
                    <b>Author(s):</b> Am ́elie Anglade, Emmanouil Benetos , Matthias Mauch and Simon Dixon 
                    <b>Date:</b> 2010
                    <b>Pages:</b> 18
                    <b>Data Source:</b> Perez-9-genres, GTZAN and ISMIR04
                    <b>Algorithms used:</b> first-order logic induction algorithm TILDE, dynamic Bayesian network (DBN),
                                            Multilayer Perceptron, SVM
                    <b>Formality rating: </b> 4/5
                    <b>Interest rating: </b> 2/5
                    <b>Genre:</b> Classical, Jazz/Blues, pop

                    <b>Intro notes:</b>
                    - majority of genre classification systems are signal-based
                    - lack high-level and contextual concepts which are as important as low-level content descriptors
                    - no attempt to integrate signal-based features with high-level harmony descriptors has been made 
                    in the literature for the human perception/characterisation of music genres
                    <b>Body Notes:</b>
                    - a new genre classification framework using both low-level signal-based features and high-level
                    harmony features
            </div>

            <div class="paper" id="g5">
                    <b>Paper Code:</b> G5
                    <b>Title:</b> Music Genre Classification
                    <b>Author(s):</b> -
                    <b>Date:</b> -
                    <b>Pages:</b> 4
                    <b>Data Source:</b> Gettysburg dataset with MFCC provided and features from Echonest
                    <b>Algorithms used:</b> support vector machines (SVM), k-nearest neighbor (k-NN) classification, 
                                            and decision trees (DT) all implemented in Python
                                            Machine learning toolkit (Milk)
                    <b>Formality rating:</b> 2/5 
                    <b>Interest rating:</b> 3/5
                    <b>Genre:</b> Country, Jazz, Pop, Rock, Techno

                    <b>Intro notes:</b>
                    <b>Body Notes:</b>
                    - Features used: time signature, energy, liveness, tempo, speechiness, mode, key, duration, loudness, 
                    danceability
                    - k-NN classifier yielded the best accuracy rate, followed by Support Vector Machine and Decision Trees
            </div>

            <div class="paper" id="g6">
                    <b>Paper Code:</b> G6
                    <b>Title:</b> Musical Genre Tag Classification With Curated and Crowdsourced Datasets
                    <b>Author(s):</b> Omar Diab, Anthony Mainero, Reid Watson
                    <b>Date:</b>
                    <b>Pages:</b> 5
                    <b>Data Source:</b> MusicBrainz, GTZAN, The Echo Nest, Last.fm
                    <b>Algorithms used:</b> Logistic Regression, Naive Bayes, SVM, k-NN
                    <b>Formality rating:</b> 2/5
                    <b>Interest rating:</b> 3/5
                    <b>Genre:</b> Blues, Country, Hiphop, Jazz, Metal, Pop, Reggae

                    <b>Intro notes:</b>
                    - interested in determining how the nature of each dataset affects each classifier’s accuracy
                    <b>Body Notes:</b>
                    - Logistic Regression and Naïve Bayes were relatively ineffective
                    - Both KNNs and SVMs produced strong results
                    - effect of curated versus crowdsourced datasets is far more significant than the difference 
                    between artist-level and track-level tagging
            </div>

            <div class="paper" id="g7">
                    <b>Paper Code:</b> G7
                    <b>Title:</b> Automatic Music Classification
                    <b>Author(s):</b> Murium Iqbal, Apoorv Khandelwal, Karanhaar Singh
                    <b>Date:</b> 2012
                    <b>Pages:</b> 38
                    <b>Data Source:</b>
                    <b>Algorithms used:</b> Naive Bayesian, Full Covariance Bayesian, SVM all implemented in Matlab
                    <b>Formality rating:</b> 2/5
                    <b>Interest rating:</b> 2/5
                    <b>Genre:</b> Rock, Rap, Classical, Country, and Techno

                    <b>Intro notes:</b>
                    <b>Body Notes:</b>
                    - Timbral Texture, Rhythmic Content, Pitch Content used
                    - SVM, Full Covariance Bayesian performed better than Naive Bayesian
            </div>

            <div class="paper" id="g8">
                    <b>Paper Code:</b> G8
                    <b>Title:</b> Classification of Music Genre
                    <b>Author(s):</b> Muralidhar Talupur, Suman Nath, Hong Yan
                    <b>Date:</b>
                    <b>Pages:</b> 12
                    <b>Data Source:</b>
                    <b>Algorithms used:</b> Neural Networks and Learning Vector Quantization
                    <b>Formality rating:</b> 2/5
                    <b>Interest rating:</b> 3/5
                    <b>Genre:</b> Classical, Rock, Jazz and Country

                    <b>Intro notes:</b>
                    <b>Body Notes:</b>
                    - Extracted group of 50 consecutive vectors each of length 128
                    - test each of the 400 vectors and then take the plurality classification, that is the 
                    largest group, as the genre of the music
                    - tried four different features to use in the whole experiment:
                    average of the FFT vectors, average of differences of successive FFT vectors, difference
                    of averages of successive FFT vectors, average of envelope of the spectrum
                    - simple averaging approach outperforms the other approaches
            </div>

            <div class="paper" id="g9">
                    <b>Paper Code:</b> G9
                    <b>Title:</b> Music Genre Classification
                    <b>Author(s):</b> Michael Haggblade, Yang Hong, Kenny Kao
                    <b>Date:</b>
                    <b>Pages:</b> 5
                    <b>Data Source:</b> GTZAN
                    <b>Algorithms used:</b> k-NN, k-means, multi-class SVM, and neural networks
                    <b>Formality rating:</b> 2/5
                    <b>Interest rating:</b> 5/5
                    <b>Genre:</b> classical, jazz, metal, and pop

                    <b>Intro notes:</b>
                    - relied purely on Mel Frequency Cepstral Coefficients (MFCC) to characterize the data
                    <b>Body Notes:</b>
                    - Kullback-Leibler divergence for distance in k-NN
                    - For k-means:
                    we chose to represent a centroid as if it were also a multi-variate Gaussian distribution 
                    of an arbitrary song (which may not actually exist in the data set), and initialized the 
                    four centroids as four random songs whose distances (as determined by KL divergence) were
                    above a certain empirically determined threshold
                    - we determined the iteration number empirically and repeatedly run k-means with different 
                    random initial centroids and pick the best, as determined by the calculated total percent 
                    accuracy
                    - For Neural Networks;
                    - pre-process the input data by combining the mean vector and the top half of the
                    covariance matrix (since it is symmetric) into one feature vector
                    -The simpler and more naive approaches, k-NN (supervised) and k-Means (unsupervised), 
                    predictably did worse than the more sophisticated neural networks (supervised) and
                    SVMs (unsupervised)
            </div>
            <div class="paper" id="g10">
                    <b>Paper Code:</b> G10
                    <b>Title:</b> A COMPARISON OF HUMAN AND AUTOMATIC MUSICAL GENRE CLASSIFICATION
                    <b>Author(s):</b> S. Lippens, J.P Martens, M. Leman, B. Baets, H. Meyer
                    <b>Date:</b>
                    <b>Pages:</b> 4
                    <b>Data Source:</b> MAMI dataset
                    <b>Algorithms used:</b> Simple Gaussian Classifier, Gaussian Mixture Model (GMM),
                                            Expectation Maximization (EM) algorithm, k-NN
                    <b>Formality rating:</b> 2/5
                    <b>Interest rating:</b> 2/5
                    <b>Genre:</b> classical, dance, pop, rap, rock, other

                    <b>Intro notes:</b>
                    - comparison of the automatic results with human genre classification on the same dataset
                    <b>Body Notes:</b>
            </div>

            <div class="paper" id="g11">
                    <b>Paper Code:</b> G11
                    <b>Title:</b> A Machine Learning Approach to Automatic Music Genre Classification 
                    <b>Author(s):</b> Carlos N. Silla Jr., Alessandro L. Koerich and Celso A. A. Kaestner 
                    <b>Date:</b> - 
                    <b>Pages:</b> 12
                    <b>Data Source:</b> Latin Music database
                    <b>Algorithms used:</b> Decision Trees, Naive-Bayes, Support Vector Machine, Multi-layer perceptron neuron nets and k Nearest Neighbours 
                    <b>Formality rating:</b> 4/5
                    <b>Interest rating:</b> 3/5
                    <b>Genre:</b> 10 different Latin genre


                    <b>Intro notes:</b> 
                        - Space decomposition done by merging of results of binary classifiers to produce final genre label.
                        - Time decomposition done by diving music according to time segments.
                        - Most important features for classification vary according to their origin in the music signal.

                    <b>Body notes:</b>
                        - Original multi-class problem is decomposed to series of binary classification problem, 
                        where most of the known classifers work better and merge to obtain final result.
                        - For Space decomposition, one-against-all(OAA) and round robin(RR) is used.
                        - Time decomposition is done into three segments- beginning, middle and end thus giving three feature sets.
                        - Time decomposition give k classification result and space dimenstion for a M-class problem produces M(OAA) 
                        or M(M-1)/2 results.
                        - For RR approach majority voting is used and rule based on the posteriori probability of the employed 
                        classifier for OAA to merge result.  
                        - For time decomposition majority vote rule is used for combining result.

            </div>
            <div class="paper" id="g12">
                    <b>Paper Code:</b> G12
                    <b>Title:</b> Musical genre classification
                    <b>Author(s):</b> Robert Neumayer
                    <b>Date:</b> -
                    <b>Pages:</b> 15
                    <b>Data Source:</b> -
                    <b>Algorithms used:</b> Multilayer perceptron
                    <b>Formality rating:</b> 3/5
                    <b>Interest rating:</b> 3/5
                    <b>Genre:</b> Metal, Punk Rock, Grunge and Hip-Hop


                    <b>Intro notes:</b>
                        - Discusses the similarities and differences between different genres according to a specific set of features.      

                    <b>Body notes:</b>
                        - Network needs anout ten times more training samples than its number of weights.
                        - 8 hidden unit gave highest accuracy.
                        - The amount of training data available also played key factor in accuracy.
                        - Selection of feature set also played key part in determining accuracy.

            </div>
            <div class="paper" id="g13">
                    <b>Paper Code:</b> G13
                    <b>Title:</b> Music Genre Classification using MFCC, SVM and BPNN
                    <b>Author(s):</b> Gursimran Kour and Neha Mehan
                    <b>Date:</b> February, 2015
                    <b>Pages:</b> 3
                    <b>Data Source:</b> Sorsa(2006)
                    <b>Algorithms used:</b> Back Propagation Neural Net and Support Vector Machine
                    <b>Formality rating:</b> 4/5
                    <b>Interest rating:</b> 4/5
                    <b>Genre:</b> -


                    <b>Intro notes:</b>
                        -Genre classification used for:-
                            a)Developing automatic playlists on MP3
                            b)Storing enormous number of songs online
                        -Classification based on MFCC

                    <b>Body notes:</b>
                        -Psychophysical studies have found the phenomena of the mel pitch scale and the critical band, and 
                        the frequency scale-warping to the mel scale has led to the cepstrum domain representation.
                        -BPNN got more accuracy than SVM.

            </div>
            <div class="paper" id="g14">
                    <b>Paper Code:</b> G14
                    <b>Title:</b> Automated Music Genre Classification
                    <b>Author(s):</b> Archit Rathore and  Margaux Dorido
                    <b>Date:</b> March 16, 2015
                    <b>Pages:</b> 2
                    <b>Data Source:</b> GTZAN genre dataset
                    <b>Algorithms used:</b> Support Vector Machine
                    <b>Formality rating:</b> 1/5
                    <b>Interest rating:</b> 1/5
                    <b>Genre:</b> Blues, Classical, Metal, Rock, Pop and Reggae


                    <b>Intro notes:</b>
                        -Mel-frequency Cepstrum(MFC) features used for representing sound based feature
                        
                    <b>Body notes:</b>
                        -MFC coefficients represent a set of short term power spectrum characteristics of the sound and have been 
                        used in the state-of-the-art recognition and sound categorisation techniques.
                        -Dataset consisted of music samples recorded under a large number of environments which is believe to aid 
                        in achievement of noise robust classifier for genres.

            </div>
            <div class="paper" id="g15">
                    <b>Paper Code:</b> G15
                    <b>Title:</b> A Comparative Study on Content-Based Music Genre Classification
                    <b>Author(s):</b> Tao Li, Mitsunori Ogihara and Qi Li
                    <b>Date:</b> -
                    <b>Pages:</b> 8
                    <b>Data Source:</b> 
                        -For Dataset A:radio, compact disks and MP3 compresses audio files 
                        -For Dataset B:CD collection
                    <b>Algorithms used:</b> Linear Discriminant Analysis, Support Vector Machine,Gaussian Mixture Models, K-Nearest 
                    Neighbors, Regression and decision trees including C4.5 and CART
                    <b>Formality rating:</b> 4/5
                    <b>Interest rating:</b> 4/5
                    <b>Genre:</b>
                        -For Dataset A:Blues, Classical, Country, Disco, Hiphop, Jazz, Metal, Pop, Reggae and Rock 
                        -For Dataset B:Ambient, Classical, Fusion, Jazz and Rock


                    <b>Intro notes:</b>
                        -Proposes new feature extraction method for music genre classification DWCHs(Daubechies Wavelet Coefficient 
                        Histograms).
                        -DWCHs capture the local and global information of music signals simultaneously by computing histograms on 
                        their Daubechies wavelet coefficients. 

                    <b>Body notes:</b>
                        -Timbral features capture the statistics of local information of music signals from a global perspective, 
                        but not enough in representing the global information of the music.
                        -Three different methods to extend SVM for multi-class: pairwise, one-against-the-rest and multi-class 
                        objective function.
                        -For Gaussian Mixture Models, three Gaussian mixtures to model each genre.
                        -DWCHs significantly improved the classification accuracy.

            </div>
            <div class="paper" id="g16">
                    <b>Paper Code:</b> G16
                    <b>Title:</b> Musical Genre Classfication of Audio Signals
                    <b>Author(s):</b> George Tzanetakis and Perry Cook
                    <b>Date:</b> July, 2002
                    <b>Pages:</b> 10
                    <b>Data Source:</b> Radio, compact disks and Mp3 compressed audio files
                    <b>Algorithm used:</b> Gaussian mixture model classifier, K-means, K-Nearest Neighbor
                    <b>Formality rating:</b> 5/5
                    <b>Interest rating:</b> 4/5
                    <b>Genre:</b> 
                        -Genre dataset:classical, country, disco, hiphop, jazz, rock, blues,reggae, pop and metal
                        -Classical dataset:choir, orchestra, piano and string quartet
                        -Jazz dataset:bigband, cool, fusion, piano, quartet and swing


                    <b>Intro notes:</b>
                        -Both whole file and real-time frame-based classification schemes are used.
                        -Timbral texture feature set is based on features used for speech and general sound classification, 
                        the other two feature sets (rhythmic and pitch content) are new and specifically designed to 
                        represent aspects of musical content (rhythm and harmony).

                    <b>Body notes:</b>
                        -Rhythmic and pitch content feature set can be computed over whole file if the the file is 
                        relatively homogeneous.
                        -Automatic segmentation algorithms can be used to segment the file into regions and apply 
                        classification to each region separately.
                        -Frames from the same audio file are never split between training and testing data in order to avoid 
                        false higher accuracy due to the similarity of feature vectors from the same file.
                        -Process is iterated with different random partitions and the results are averaged to ensure that the 
                        calculated accuracy will not be biased because of a particular partitioning of training and testing.
                        -Change of texture window size affected he classification accuracy.
                        -From use of individual feature set for task of automatic musical genre classification, it was seen that 
                        the nontimbral texture features pitch histogram features (PHF) and beat histogram features (BHF) performed 
                        worse than the timbral-texture features (STFT, MFCC) in all cases.
                    
            </div>
            <div class="paper" id="g17">
                    <b>Paper Code:</b> G17
                    <b>Title:</b> Automatic Musical Genre Classification Of Audio Signals
                    <b>Author(s)</b> George Tzanetakis, Georg Essl and Perry Cook
                    <b>Date:</b> -
                    <b>Pages:</b> 6
                    <b>Data Source:</b> Compact disks, radio and web
                    <b>Algorithm used:</b> Gaussian classifier
                    <b>Formality rating:</b> 5/5
                    <b>Interest rating:</b> 4/5
                    <b>Genre:</b>
                        -Genre dataset:classical, country, disco, hiphop, jazz and rock
                        -Classical dataset:choral, orchestral, piano and string 4tet


                    <b>Intro notes:</b>
                        -Audio signals can be automatically classfied using a hierarchy of genres that can be represented as a 
                        tree with 15 nodes.

                    <b>Body notes:</b>
                        -Musical surface features denote the characteristics of music related to texture, timbre and instrumentation 
                        and for its representation 9-dimensional feature vector is used which are:mean-Centroid, mean-Rolloff, 
                        mean-Flux, mean-ZeroCrossings, std-Centroid, std-Rolloff, std-Flux, std-ZeroCrossings and LowEnergy.
                        -Rhythmic feature set is based on detecting the most salient periodicities of the signal.

            </div>

    </div>
    </body>
</html>

